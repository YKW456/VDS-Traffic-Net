#!/usr/bin/env python3
"""
ResNet34æ¨¡å‹å›¾ç‰‡é¢„æµ‹è„šæœ¬ - 46åˆ†ç±»å¹²æ‰°å…‰è¯†åˆ«
"""
import os
import time
import torch
import pandas as pd
import numpy as np
from PIL import Image
from torchvision import transforms
from train_vds_no_ewc import create_resnet34_pretrained
import glob

class InterferenceLightPredictor:
    def __init__(self, model_path, device=None):
        """
        åˆå§‹åŒ–å¹²æ‰°å…‰ç±»å‹é¢„æµ‹å™¨ - ResNet34æ¨¡å‹

        Args:
            model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        self.device = device if device else torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # æ•°æ®é¢„å¤„ç†ï¼ˆä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
        self.transform = transforms.Compose([
            transforms.Resize(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])

        # 46ä¸ªå¹²æ‰°å…‰ç±»åˆ« - æŒ‰æ•°å­—é¡ºåºæ’åˆ—ï¼Œç¡®ä¿ç´¢å¼•iå¯¹åº”ç±»åˆ«i
        self.class_names = [str(i) for i in range(46)]  # ['0', '1', '2', ..., '45']
        self.num_classes = 46

        # éªŒè¯ç±»åˆ«æ˜ å°„ï¼šç´¢å¼•iåº”è¯¥å¯¹åº”ç±»åˆ«åç§°str(i)
        print(f"ğŸ“‹ ç±»åˆ«æ˜ å°„éªŒè¯:")
        for i in range(min(10, len(self.class_names))):
            print(f"   ç´¢å¼•{i} â†’ ç±»åˆ«'{self.class_names[i]}'")
        if len(self.class_names) > 10:
            print(f"   ... (å…±{len(self.class_names)}ä¸ªç±»åˆ«)")
        print(f"   ç´¢å¼•{len(self.class_names)-1} â†’ ç±»åˆ«'{self.class_names[-1]}'")
        print(f"   âœ… æ˜ å°„è§„åˆ™: ç´¢å¼•i â†’ ç±»åˆ«'{i}'")

        # åŠ è½½æ¨¡å‹
        self.model = self._load_model(model_path)

        print(f"âœ… ResNet34å¹²æ‰°å…‰é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   ç±»åˆ«æ•°: {self.num_classes}")
        print(f"   æ¨¡å‹æ¶æ„: ResNet34é¢„è®­ç»ƒ")
        print(f"   æ¨¡å‹è·¯å¾„: {model_path}")
    
    def _load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„ResNet34æ¨¡å‹"""
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        print(f"ğŸ”„ æ­£åœ¨åŠ è½½ResNet34æ¨¡å‹: {model_path}")

        # åˆ›å»ºResNet34æ¨¡å‹ï¼ˆ46ä¸ªç±»åˆ«ï¼‰
        model = create_resnet34_pretrained(num_classes=self.num_classes)

        # åŠ è½½æƒé‡
        try:
            state_dict = torch.load(model_path, map_location=self.device)

            # éªŒè¯æƒé‡å½¢çŠ¶
            if 'fc.weight' in state_dict:
                fc_weight_shape = state_dict['fc.weight'].shape
                model_classes = fc_weight_shape[0]

                if model_classes != self.num_classes:
                    raise ValueError(f"æ¨¡å‹ç±»åˆ«æ•°ä¸åŒ¹é…: æœŸæœ›{self.num_classes}, å®é™…{model_classes}")

                print(f"âœ… æƒé‡éªŒè¯é€šè¿‡: {model_classes}ä¸ªç±»åˆ«")

            model.load_state_dict(state_dict)
            print(f"âœ… ResNet34æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")

        except Exception as e:
            print(f"âŒ ResNet34æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            raise

        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        model.to(self.device)

        return model
    
    def predict_single_image(self, image_path):
        """
        é¢„æµ‹å•å¼ å›¾ç‰‡
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            
        Returns:
            tuple: (predicted_class, class_name, confidence, prediction_time, top5_predictions)
        """
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.time()

        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # æ¨¡å‹é¢„æµ‹
            with torch.no_grad():
                output = self.model(input_tensor)
                probabilities = torch.softmax(output, dim=1)

                # è·å–æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
                confidence, predicted_class = torch.max(probabilities, 1)
                predicted_class = predicted_class.item()
                confidence = confidence.item()
                class_name = self.class_names[predicted_class]

                # è·å–Top5é¢„æµ‹
                top5_probs, top5_classes = torch.topk(probabilities, 5, dim=1)
                top5_predictions = []
                for i in range(5):
                    cls_idx = top5_classes[0][i].item()
                    cls_prob = top5_probs[0][i].item()
                    top5_predictions.append((cls_idx, self.class_names[cls_idx], cls_prob))

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            prediction_time = end_time - start_time

            return predicted_class, class_name, confidence, prediction_time, top5_predictions

        except Exception as e:
            print(f"âŒ é¢„æµ‹å›¾ç‰‡å¤±è´¥: {image_path}, é”™è¯¯: {str(e)}")
            end_time = time.time()
            prediction_time = end_time - start_time
            return -1, "error", 0.0, prediction_time, []
    
    def predict_folder(self, folder_path, output_csv_path):
        """
        é¢„æµ‹æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰å›¾ç‰‡
        
        Args:
            folder_path: å›¾ç‰‡æ–‡ä»¶å¤¹è·¯å¾„
            output_csv_path: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(folder_path):
            print(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
            return None
        
        print(f"\nğŸ“ å¼€å§‹é¢„æµ‹æ–‡ä»¶å¤¹: {folder_path}")
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        image_files = []
        for ext in image_extensions:
            image_files.extend(glob.glob(os.path.join(folder_path, ext)))
            image_files.extend(glob.glob(os.path.join(folder_path, ext.upper())))
        
        image_files.sort()  # æŒ‰æ–‡ä»¶åæ’åº
        
        if not image_files:
            print(f"âŒ æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {folder_path}")
            return None
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
        
        # é¢„æµ‹ç»“æœåˆ—è¡¨
        results = []
        total_time = 0
        
        # é€å¼ é¢„æµ‹
        for i, image_path in enumerate(image_files):
            image_name = os.path.basename(image_path)
            
            # é¢„æµ‹å•å¼ å›¾ç‰‡
            predicted_class, class_name, confidence, prediction_time, top5_predictions = self.predict_single_image(image_path)
            total_time += prediction_time

            # è®°å½•ç»“æœ
            result = {
                'Image_Name': image_name,
                'Image_Path': image_path,
                'Predicted_Class': predicted_class,
                'Predicted_Class_Name': class_name,
                'Confidence': confidence,
                'Prediction_Time_Seconds': prediction_time,
                'Prediction_Time_MS': prediction_time * 1000,
                'Top2_Class': top5_predictions[1][0] if len(top5_predictions) > 1 else -1,
                'Top2_Confidence': top5_predictions[1][2] if len(top5_predictions) > 1 else 0.0,
                'Top3_Class': top5_predictions[2][0] if len(top5_predictions) > 2 else -1,
                'Top3_Confidence': top5_predictions[2][2] if len(top5_predictions) > 2 else 0.0
            }
            results.append(result)

            # æ˜¾ç¤ºè¿›åº¦
            if (i + 1) % 10 == 0 or i == 0 or i == len(image_files) - 1:
                avg_time = total_time / (i + 1)
                top3_info = f"Top3: {top5_predictions[0][0]},{top5_predictions[1][0] if len(top5_predictions)>1 else 'N/A'},{top5_predictions[2][0] if len(top5_predictions)>2 else 'N/A'}" if top5_predictions else ""
                print(f"   è¿›åº¦: {i+1}/{len(image_files)}, "
                      f"å›¾ç‰‡: {image_name}, "
                      f"é¢„æµ‹: ç±»åˆ«{predicted_class} (ç½®ä¿¡åº¦: {confidence:.4f}), "
                      f"è€—æ—¶: {prediction_time*1000:.2f}ms, "
                      f"{top3_info}")
        
        # ä¿å­˜ç»“æœåˆ°CSV
        df = pd.DataFrame(results)
        df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
        
        # ç»Ÿè®¡ä¿¡æ¯
        avg_time = total_time / len(image_files)
        max_time = max([r['Prediction_Time_Seconds'] for r in results])
        min_time = min([r['Prediction_Time_Seconds'] for r in results])
        
        print(f"\nğŸ“Š é¢„æµ‹å®Œæˆç»Ÿè®¡:")
        print(f"   æ€»å›¾ç‰‡æ•°: {len(image_files)}")
        print(f"   æ€»è€—æ—¶: {total_time:.4f}ç§’")
        print(f"   å¹³å‡è€—æ—¶: {avg_time*1000:.2f}ms")
        print(f"   æœ€å¤§è€—æ—¶: {max_time*1000:.2f}ms")
        print(f"   æœ€å°è€—æ—¶: {min_time*1000:.2f}ms")
        print(f"   ç»“æœä¿å­˜: {output_csv_path}")
        
        # ç±»åˆ«ç»Ÿè®¡
        class_counts = df['Predicted_Class_Name'].value_counts()
        print(f"\nğŸ“ˆ é¢„æµ‹ç±»åˆ«ç»Ÿè®¡:")
        for class_name, count in class_counts.items():
            percentage = count / len(df) * 100
            print(f"   {class_name}: {count} å¼  ({percentage:.1f}%)")
        
        return results


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”® ResNet34å¹²æ‰°å…‰ç±»å‹é¢„æµ‹ä¸æ—¶é—´ç»Ÿè®¡")
    print("=" * 60)

    # é…ç½®å‚æ•°
    model_path = "./model_save/train_vds_no_ewc_best_model.pth"  # ResNet34æ¨¡å‹è·¯å¾„
    folder_5nd_1 = "5nd_2"  # ç¬¬5ä¸ªåŠŸèƒ½ç”Ÿæˆçš„å›¾ç‰‡
    folder_6nd_1 = "6nd_2"  # ç¬¬6ä¸ªåŠŸèƒ½ç”Ÿæˆçš„å›¾ç‰‡
    output_dir = "data_save"

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè¿è¡Œ train_vds_no_ewc.py è®­ç»ƒResNet34æ¨¡å‹")
        return
    
    # æ£€æŸ¥æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
    folders_to_predict = []
    if os.path.exists(folder_5nd_1):
        folders_to_predict.append((folder_5nd_1, "5nd_1_resnet34_predictions.csv"))
    else:
        print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_5nd_1}")

    if os.path.exists(folder_6nd_1):
        folders_to_predict.append((folder_6nd_1, "6nd_1_resnet34_predictions.csv"))
    else:
        print(f"âš ï¸ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_6nd_1}")

    if not folders_to_predict:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è¦é¢„æµ‹çš„æ–‡ä»¶å¤¹")
        return

    try:
        # åˆå§‹åŒ–é¢„æµ‹å™¨
        predictor = InterferenceLightPredictor(model_path)
        
        # è®°å½•æ€»å¼€å§‹æ—¶é—´
        total_start_time = time.time()
        
        # å¯¹æ¯ä¸ªæ–‡ä»¶å¤¹è¿›è¡Œé¢„æµ‹
        all_results = {}
        for folder_path, output_filename in folders_to_predict:
            output_csv_path = os.path.join(output_dir, output_filename)
            results = predictor.predict_folder(folder_path, output_csv_path)
            if results:
                all_results[folder_path] = results
        
        # è®°å½•æ€»ç»“æŸæ—¶é—´
        total_end_time = time.time()
        total_duration = total_end_time - total_start_time
        
        # æ€»ä½“ç»Ÿè®¡
        print(f"\n" + "=" * 60)
        print(f"ğŸ‰ æ‰€æœ‰é¢„æµ‹å®Œæˆï¼")
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
        print(f"   æ€»è€—æ—¶: {total_duration:.4f}ç§’")
        print(f"   é¢„æµ‹æ–‡ä»¶å¤¹æ•°: {len(all_results)}")
        
        total_images = sum(len(results) for results in all_results.values())
        if total_images > 0:
            avg_time_per_image = total_duration / total_images
            print(f"   æ€»å›¾ç‰‡æ•°: {total_images}")
            print(f"   å¹³å‡æ¯å¼ å›¾ç‰‡è€—æ—¶: {avg_time_per_image*1000:.2f}ms")
        
        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        for folder_path, output_filename in folders_to_predict:
            if folder_path in all_results:
                output_path = os.path.join(output_dir, output_filename)
                print(f"   {folder_path} -> {output_path}")
        
    except Exception as e:
        print(f"âŒ é¢„æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
